[
  {
    "id": 6,
    "title": "Swarm-Tune",
    "description": "A decentralized AI fine-tuning swarm — nodes discover each other over libp2p, exchange raw PyTorch gradients across the mesh, average them without any central server, and collectively fine-tune a model inside a Docker-simulated network on a single machine.",
    "highlights": [
      "Phase 1: Whisper Network — libp2p P2P node discovery & messaging, no central server",
      "Phase 2: Gradient Math — manual PyTorch gradient extraction, bypassing DDP for network transit",
      "Phase 3: Synchronisation — nodes exchange & average gradients across libp2p; straggler-problem handling",
      "Phase 4: Docker Simulation — 4-container swarm on M4 Pro collectively fine-tuning a model"
    ],
    "tags": ["libp2p", "PyTorch", "Distributed ML", "Docker", "P2P", "Python"],
    "status": "In Progress",
    "github": null,
    "demo": null
  },
  {
    "id": 5,
    "title": "Sentinel-Shield",
    "description": "An AI security gateway that sits between your app and OpenAI / Anthropic / Ollama — stripping PII, blocking prompt injections, scanning responses for leaks, enforcing rate limits, and emitting a full audit trail. Drop-in proxy, Docker-ready.",
    "tags": ["Security", "AI Gateway", "Docker", "Prometheus", "Python", "SQLite"],
    "status": "Live",
    "github": "https://github.com/yashasviudayan-py/Sentinel-Shield",
    "demo": null
  },
  {
    "id": 1,
    "title": "The Orchestrator",
    "description": "A natural language interface to control and orchestrate multiple AI agents from a single terminal. Think tmux meets AI — dispatch tasks, monitor pipelines, and collect results.",
    "tags": ["Multi-Agent", "CLI", "Ollama", "Python"],
    "status": "Live",
    "github": "https://github.com/yashasviudayan-py/the-orchestrator",
    "demo": null
  },
  {
    "id": 2,
    "title": "PR Agent",
    "description": "Automated code review agent that analyzes pull requests, suggests improvements, detects potential bugs, and generates meaningful commit messages using local LLMs.",
    "tags": ["Local LLM", "Git", "Python", "FastAPI"],
    "status": "Live",
    "github": "https://github.com/yashasviudayan-py/pr-agent",
    "demo": null
  },
  {
    "id": 3,
    "title": "Context Core",
    "description": "A persistent memory layer for AI assistants. Stores, retrieves, and compresses conversation context using vector embeddings to give LLMs long-term memory without token bloat.",
    "tags": ["Vector DB", "Embeddings", "RAG", "TypeScript"],
    "status": "Live",
    "github": "https://github.com/yashasviudayan-py/context-core",
    "demo": null
  },
  {
    "id": 4,
    "title": "The Autonomous Researcher",
    "description": "An AI agent that autonomously browses the web, synthesizes information, and produces structured research reports. Powered by Llama-3 via Ollama with a multi-step planning pipeline.",
    "tags": ["Llama-3", "Ollama", "LangChain", "Python"],
    "status": "Live",
    "github": "https://github.com/yashasviudayan-py/autonomous-researcher",
    "demo": null
  }
]
